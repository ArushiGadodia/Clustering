import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_iris
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.decomposition import PCA

from sklearn.cluster import (
    KMeans,
    AgglomerativeClustering,
    DBSCAN,
    MeanShift
)
from sklearn.mixture import GaussianMixture

from sklearn.metrics import (
    silhouette_score,
    calinski_harabasz_score,
    davies_bouldin_score
)

# 1. Load data
iris = load_iris()
X = iris.data

# 2. Define preprocessing pipelines
preprocessors = {
    'No Processing': lambda X: X,
    'Normalization': lambda X: MinMaxScaler().fit_transform(X),
    'Standardization': lambda X: StandardScaler().fit_transform(X),
    'PCA (2D)': lambda X: PCA(n_components=2, random_state=42).fit_transform(X),
    'Std → Norm': lambda X: MinMaxScaler().fit_transform(StandardScaler().fit_transform(X)),
    'Std → Norm → PCA': lambda X: PCA(n_components=2, random_state=42).fit_transform(
        MinMaxScaler().fit_transform(StandardScaler().fit_transform(X))
    ),
}

# 3. Define clustering algorithms (as factories accepting n_clusters)
clustering_algos = {
    'KMeans':          lambda k: KMeans(n_clusters=k, random_state=42),
    'Agglomerative':   lambda k: AgglomerativeClustering(n_clusters=k),
    'DBSCAN':          lambda k: DBSCAN(eps=0.5, min_samples=5),  # DBSCAN does not require 'n_clusters'
    'MeanShift':       lambda k: MeanShift(bandwidth=2),           # Mean Shift does not require 'n_clusters'
    'GaussianMixture': lambda k: GaussianMixture(n_components=k, random_state=42)
}

# 4. Evaluation metrics
metrics = {
    'Silhouette': silhouette_score,
    'Calinski–Harabasz': calinski_harabasz_score,
    'Davies–Bouldin': davies_bouldin_score
}

# 5. Run experiments
cluster_counts = [3, 4, 5]
results = {}  # results[algo][metric] = DataFrame

for algo_name, algo_factory in clustering_algos.items():
    # prepare an empty DataFrame per metric
    dfs = {m: pd.DataFrame(index=preprocessors.keys(),
                          columns=[f'c={k}' for k in cluster_counts])
           for m in metrics}
    
    for pp_name, pp_fn in preprocessors.items():
        X_p = pp_fn(X)
        
        for k in cluster_counts:
            # fit clustering
            model = algo_factory(k) if algo_name not in ['DBSCAN', 'MeanShift'] else algo_factory(None)
            if algo_name == 'GaussianMixture':
                labels = model.fit_predict(X_p)
            elif algo_name in ['DBSCAN', 'MeanShift']:
                labels = model.fit(X_p).labels_  # For DBSCAN and MeanShift, labels are obtained like this
            else:
                labels = model.fit(X_p).labels_
            
            # compute metrics
            for m_name, m_fn in metrics.items():
                # Silhouette and Calinski require >1 cluster and <n_samples
                try:
                    score = m_fn(X_p, labels)
                except Exception:
                    score = np.nan
                dfs[m_name].loc[pp_name, f'c={k}'] = round(score, 4)
    
    results[algo_name] = dfs

# 6. Display tables and generate comparative graphs
for algo_name, dfs in results.items():
    print(f"\n=== Using {algo_name} Clustering ===\n")
    for m_name, df in dfs.items():
        print(f"-- {m_name} --")
        display(df)   # in Colab/Jupyter this will nicely render; else use print(df)

# 7. Generate Comparative Graphs for each Metric
# Prepare for plotting
for m_name in metrics.keys():
    # Create a dataframe for each metric to plot
    all_results = []
    
    for algo_name, dfs in results.items():
        df = dfs[m_name]
        df['Algorithm'] = algo_name  # Add the algorithm name to the DataFrame for identification
        all_results.append(df)
    
    # Concatenate all results into one DataFrame
    final_df = pd.concat(all_results, axis=0)
    final_df = final_df.reset_index().melt(id_vars=['index', 'Algorithm'], var_name='Cluster Count', value_name='Score')

    # Plotting the results
    plt.figure(figsize=(10, 6))
    sns.set_theme(style="whitegrid")
    sns.boxplot(x="Cluster Count", y="Score", hue="Algorithm", data=final_df, showmeans=True)
    plt.title(f'Comparative Boxplot for {m_name} Score across Clustering Algorithms')
    plt.show()
